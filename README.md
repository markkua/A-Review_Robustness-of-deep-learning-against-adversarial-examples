Literature review of *Robustness of deep learning against adversarial examples*  (Geomatics Seminar at d'BAUG, ETH Zurich)

## Literatures:
- I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.
- A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.
- D. Su, H. Zhang, H. Chen, J. Yi, P.-Y. Chen, and Y. Gao. Is robustness the cost of accuracy?– a comprehensive study on the robustness of 18 deep image classification models. In Pro- ceedings of the European Conference on Computer Vision (ECCV), pages 631–648.
- C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
- C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.
- F. Tramèr, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel. The space of transferable adversarial examples. arXiv preprint arXiv:1704.03453, 2017.
- A. Wang, H. Zhou, W. Xu, and X. Chen. Deep neural network capacity. arXiv preprint arXiv:1708.05029, 2017.
- H. Zhang, Y. Yu, J. Jiao, E. P. Xing, L. E. Ghaoui, and M. I. Jordan. Theoretically principled trade-off between robustness and accuracy. arXiv preprint arXiv:1901.08573, 2019.


## [Report](https://github.com/markkua/A-Review_Robustness-of-deep-learning-against-adversarial-examples/blob/master/Report/Report-Robustness%20of%20deep%20learning%20against%20adversarial%20examples.pdf)

## [Presentation slides](https://github.com/markkua/A-Review_Robustness-of-deep-learning-against-adversarial-examples/blob/master/Presentation/Geomatic_Seminar_Robustness_BingxinKe.pdf)

